{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LenetでMNIST\n",
    "\n",
    "#### 原論文\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-99.pdf\n",
    "#### ChainerのMNISTチュートリアル\n",
    "https://docs.chainer.org/en/stable/examples/mnist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer.backends import cuda\n",
    "from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Chain):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(\n",
    "                in_channels=1, out_channels=6, ksize=5, stride=1)\n",
    "            self.conv2 = L.Convolution2D(\n",
    "                in_channels=6, out_channels=16, ksize=5, stride=1)\n",
    "            self.fc3 = L.Linear(None, 84)\n",
    "            self.fc4 = L.Linear(84, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.relu(self.fc3(h))\n",
    "        if chainer.config.train:\n",
    "            return self.fc4(h)\n",
    "        return F.softmax(self.fc4(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.mnist.get_mnist(ndim=3)\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "gpu_id = -1\n",
    "max_epoch = 10\n",
    "model = L.Classifier(model)\n",
    "optimizer = optimizers.MomentumSGD()\n",
    "optimizer.setup(model)\n",
    "updater = training.updaters.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='mnist_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.training import extensions\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "1           0.40473     0.875983       1.51474               0.964399                  51.2284       \n",
      "2           0.103885    0.968817       1.49234               0.979233                  113.398       \n",
      "3           0.0739544   0.977079       1.49047               0.980716                  174.218       \n",
      "4           0.0601382   0.981153       1.48494               0.983881                  227.164       \n",
      "5           0.0520363   0.983775       1.48491               0.983584                  278.809       \n",
      "6           0.0460341   0.985674       1.48123               0.986254                  335.385       \n",
      "7           0.0411847   0.987007       1.48095               0.985858                  391.664       \n",
      "8           0.0359454   0.988598       1.47805               0.987935                  443.785       \n",
      "9           0.0336231   0.989356       1.47759               0.98843                   497.156       \n",
      "10          0.0295642   0.990688       1.47607               0.988726                  551.004       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
